# Einfache Hypothesentests

```{r echo=F, message=FALSE, warning=FALSE}
options(scipen = 999)
library(papaja)
```

## Ein-Stichproben t-Test

```{r}
data = read.csv("data/One sample t-test.csv")
names(data) = c("gewicht", "groesse")
```

### Hypothesen

Mit einem Ein-Stichproben t-Test vergleichen wir den Mittelwert einer Gruppe mit einem hypothetischen Mittelwert. 

Der Test prüft also anhand des Mittelwerts einer Stichprobe, ob der Erwartungswert in der entsprechenden Population gleich einem vorgegebenen Wert ist (dem unter $H_{0}$ erwarteten $μ_{0}$).

Es sind folgende Hypothesen denkbar:

Test auf Unterschiedlichkeit von dem Referenzwert (ungerichtet):

* $H_0$: $μ=μ_{0}$
* $H_1$: $μ\neqμ_0$

Test, ob Mittelwert größer/kleiner als Referenzwert ist (gerichtet):

* $H_0$: $μ≤μ_{0}$; $H_1$: $μ>μ_{0}$ 
* $H_0$: $μ≥μ_{0}$; $H_1$: $μ<μ_{0}$

Zum Beispiel könnten wir eine Stichprobe von Menschen aus Deutschland erhoben haben und uns dafür interessieren, ob diese signifikant größer, bzw. kleiner als der Durchschnitt in Deutschland sind.

Die ersten Zeilen des Stichprobendatensatzes könnten so aussehen:
```{r echo=FALSE}
head(data)
```

Zunächst brauchen wir einen hypothetischen Vergleichswert. Sucht man die geschlechterübergreifende Durchschnittsgröße in Deutschland im Internet findet man einen Wert von ca. 173 cm. 

### Deskriptive Einordnung

Die Berechnung unseres Mittelwerts ist einfache Deskriptivstatistik:

```{r}
mean(data$groesse)
```

Der Sachverhalt lässt sich auch graphisch darstellen:

```{r}
ggplot(data = data, aes(x = groesse)) +
  geom_histogram(bins = 40, fill = "black") +
  labs(x = "Größe", y = "N") +
  geom_vline(xintercept = 173, linetype = "dashed", colour = "red") +
  geom_vline(xintercept = mean(data$groesse), linetype = "dashed", colour = "green") +
  theme_classic() 
```

Die grüne Linie im Zentrum des Histogramms stellt unseren Stichprobenmittelwert dar. Die rote Linie ist der angenommene Mittelwert in der Population von 173 cm.

### Test durchführen

Zur Durchführung des Tests nutzen wir die in der Grundform von R vorinstallierte `t.test()` Funktion. 
```{r}
t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)
```
Wir wählen die Variable `groesse` innerhalb unseres Datensatzes mit dem `$` Zeichen an. Über das `mu` Argument geben wir den hypothetischen Vergleichswert an. Unter `alternative` können wir auswählen, ob der Test gerichtet oder ungerichtet (aka ein- oder zweiseitig) durchgeführt werden soll. Je nach Hypothese wählen wir `"two.sided"` für einen ungerichteten Test und entweder `"less"` oder `"greater"` für einen gerichteten Test. Das `conf.level` entsprich unserem  Signifikanzniveau. 

### Ergebnis interpretieren

Das Ergebnis des Tests lässt sich am P-Wert ablesen (p=`r t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$p.value`). Ist der P-wert kleiner als das gewählte Signifikanzniveau (i.d.R $\alpha=.05$) unterscheidet sich unser Stichprobenmittelwert (`r round(mean(data$groesse), 2)` cm) signifikant von der Durchschnittsgröße in Deutschland (173 cm). Wir verwerfen also die Nullhypothese (H0) zugunsten unserer Alternativhypothese (H1).

### Ergebnis berichten

Die relevanten Parameter zum Berichten eines Ein-Stichproben t-Tests sind

* M (Mittelwert)
* Grenzen des Konfidenzintervalls des Mittelwerts
* t-Wert (Teststatistik)
* df (Freiheitsgerade)
* P-Wert

Beim Berichten im Fließtext schreibt man: 

Die Größe in der Stichpobe unterschied sich signifikant von der Durchschnittsgröße in Deutschland (173 cm),  M = `r round(t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$estimate, 2)`, 95% CI (`r round(t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$conf.int[1], 2)`, `r round(t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$conf.int[2], 2)`), t (`r round(t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$parameter, 2)`) = `r round(t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$statistic, 2)`; p < .001.

Diese Werte lassen sich wie folgt aus dem t-Test Objekt extrahieren:

t-Wert (Teststatistik):
```{r}
t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$statistic
```

df (Freiheitsgerade):
```{r}
t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$parameter
```

P-Wert:
```{r}
t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$p.value
```

Grenzen des Konfidenzintervalls (unten & oben):
```{r}
t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$conf.int[1]
t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)$conf.int[2]
```

### Effektstärke 

#### Cohen's d

Die am häufigsten verwendete Effektstärke für den Ein-Stichproben t-Test ist Cohen's d @cohen1988statistical.
Cohen's d lässt sich mit dem Paket `effsize` berechnen. Dieses verwendet praktischerweise die gleiche Schreibweise, wie der t-Test:

```{r}
effsize::cohen.d(data$groesse, f = NA, mu = 173)
```

Auch die Einzelparameter von Cohen's d lassen sich extrahieren:

Cohen's d:
```{r}
effsize::cohen.d(d = data$groesse, f = NA, mu = 173)$estimate
```

Grenzen des Konfidenzintervalls (unten & oben):
```{r}
effsize::cohen.d(d = data$groesse, f = NA, mu = 173)$conf.int[1]
effsize::cohen.d(d = data$groesse, f = NA, mu = 173)$conf.int[2]
```

Die Interpretation von Cohens'd lautet wie folgt @cohen1992quantitative:

```{r echo = F}
d = data.frame("d" = c("|>0.2|",
                       "|>0.5|",
                       "|>0.8|"),
               Interpretation = c("kleiner Effekt",
                                  "mittlerer Effekt",
                                  "großer Effekt"))
apa_table(d, caption = "Interpretation von Cohen's d.")
```

### Darstellung in Tabellenform

Zur sauberen Darstellung des Ergebnisses in einer bereits nach APA formatierten Tabelle, lassen sich die Funktionen `apa_print` und `apa_table` aus dem Paket `papaja` verwenden.

```{r}
library(papaja)
apa_test <- apa_print(
  t.test(data$groesse, mu = 173, alternative = "two.sided", conf.level = 0.95)
)
apa_table(
  apa_test$table, caption = "Tabelle für den Ein-Stichproben t-Test."
)
```


## t-Test bei unabhängigen Stichproben

```{r include=FALSE}
data = read.csv("data/Independent t-test.csv")
```
### Hypothesen

Mit einem unabhängigen t-Test vergleichen wir die Mittelwerte von 2 unabhängigen Gruppen. Im Datensatz müssen zwei Variablen vorhanden sein, eine numerische Variable (AV), für die Mittelwerte berechnet werden können und eine dichotome Gruppenvariable (UV).

Es sind folgende Hypothesen denkbar:

Test auf Unterschiedlichkeit der beiden Gruppenmittelwerte (ungerichtet):

* $H_0$: $μ_1=μ_2$ bzw. $μ_1−μ_2=0$ und $σ_1=σ_2=σ$
* $H_1$: $μ_1\neqμ_2$ bzw. $μ_1−μ_2\neq0$ und $σ_1=σ_2=σ$ 

Test, ob Mittelwert der einen Gruppe größer/kleiner als Mittelwert der anderen Gruppe ist (gerichtet):

* $H_0$: $μ_1\leqμ_2$ bzw. $μ_1−μ_2\leq0$ und $σ_1=σ_2=σ$
* $H_1$: $μ_1>μ_2$ bzw. $μ_1−μ_2>0$ und $σ_1=σ_2=σ$


Zum Beispiel könnten wir eine Stichprobe bestehend aus Männern und Frauen erhoben haben, die eine Diät durchgeführt haben. Eine Fragestellung könnte sein, ob Männer und Frauen (Geschlecht = dichotome UV) unterschiedlich viel abgenommen haben (Gewichtsverlust = numerische AV).

Die ersten Zeilen des Stichprobendatensatzes könnten so aussehen:
```{r echo=FALSE}
head(data)
```

### Deskriptive Einordnung

Zunächst können wir uns die Deskriptivstatistiken innerhalb der beiden Gruppen einmal anschauen:

```{r}
psych::describeBy(Weight.loss ~ Gender, data = data)
```

Rein deskriptiv lässt sich bereits feststellen, dass Männer mit `r round(mean(data$Weight.loss[data$Gender == "Males"]), 2)`kg etwas weniger abgenommen zu haben scheinen, als Frauen mit `r round(mean(data$Weight.loss[data$Gender == "Males"]), 2)`kg. 

Ob sich dieser numerische Unterschied auch als signifikant erweist, prüfen wir mit dem t-Test.

### Test durchführen

Zur Durchführung des Tests nutzen wir die in der Grundform von R vorinstallierte `t.test()` Funktion. 

Die Schreibweise in Formelformat nimmt die Form `AV ~ UV` an, wobei `~` soviel heißt wie "wird vorhergesagt durch".

```{r}
t.test(Weight.loss ~ Gender, data = data)
```

Alternative Schreibweise:

```{r}
t.test(data$Weight.loss[data$Gender == "Males"], data$Weight.loss[data$Gender == "Females"])
```

Für einen gerichteten Test (z.B. Frauen nehmen mehr ab als Männer)

```{r}
t.test(Weight.loss ~ Gender, data = data, alternative = "greater")
```

### Relevante Parameter extrahieren

Die relevanten Parameter zum Berichten eines unabhängigen t-Tests sind:

* $\Delta$M (Differenz vom Mittelwert zum Referenzwert)
* Grenzen des Konfidenzintervalls der Mittelwertsdifferenz
* t-Wert (Teststatistik)
* df (Freiheitsgerade)
* P-Wert

Diese Werte lassen sich wie folgt aus dem t-Test Objekt extrahieren:

t-Wert (Teststatistik):
```{r}
t.test(Weight.loss ~ Gender, data = data)$statistic
```

df (Freiheitsgerade):
```{r}
t.test(Weight.loss ~ Gender, data = data)$parameter
```

P-Wert:
```{r}
t.test(Weight.loss ~ Gender, data = data)$p.value
```

Grenzen des Konfidenzintervalls (unten & oben):
```{r}
t.test(Weight.loss ~ Gender, data = data)$conf.int[1]
t.test(Weight.loss ~ Gender, data = data)$conf.int[2]
```

### Voraussetzungsprüfung und Alternativen

Folgende Vorraussetzungen gelten für den unabhängigen t-Test:
* unabhängige Messungen
* Intervallskala
* Normalverteilung in beiden Gruppen 
* Homogenität der Varianzen

Sollten die Vorraussetzungen Intervallskalekniveau und Normalverteilung verletzt sein, muss ein robuster Test gerechnet werden (s.u. U-Test).

Die Varianzhomogenität wird mittels Levene's Test (F-Test) geprüft @levene1960robust. Eine Funktion dafür ist im Patek `car` enthalten.

```{r}
car::leveneTest(Weight.loss ~ Gender, data = data)
```

Ein signifikanter Levene's Test bedeutet, dass sich die Varianzen innerhalb der Gruppen signifikant unterscheiden. Sie sind also nicht "homogen".

Zum Berichten eines Levene's Test gibt es nicht viel zu tun. Lediglich die Freiheitsgrade, der F-Wert und die Signifikanz sind zu berichten. Die übliche Form hierfür ist die folgende: F(1,49) = 16,908, p = 0,0001493

Liegt keine Varianzhomogenität vor, berechnet man stattdessen einen **Welch-Test**.

Um einen **Welch-Test** zu berechnen, ändern wir nur leicht die Funktion:
```{r}
t.test(Weight.loss ~ Gender, data = data, var.equal = FALSE)
```

### Effektstärke

#### Cohen's d

Die am häufigsten verwendete Effektstärke für den Vergleich zweier unabhängiger Gruppen ist Cohen's d @cohen1988statistical.
Cohen's d lässt sich mit dem Paket `effsize` berechnen. Dieses verwendet praktischerweise die gleiche Schreibweise, wie der t-Test:

```{r}
effsize::cohen.d(Weight.loss ~ Gender, data = data)
```

Auch die Einzelparameter von Cohen's d lassen sich extrahieren:

Cohen's d:
```{r}
effsize::cohen.d(Weight.loss ~ Gender, data = data)$estimate
```

Grenzen des Konfidenzintervalls (unten & oben):
```{r}
effsize::cohen.d(Weight.loss ~ Gender, data = data)$conf.int[1]
effsize::cohen.d(Weight.loss ~ Gender, data = data)$conf.int[2]
```

Die Interpretation von Cohens'd lautet wie folgt @cohen1992quantitative:

```{r echo = F}
d = data.frame("d" = c("|>0.2|",
                       "|>0.5|",
                       "|>0.8|"),
               Interpretation = c("kleiner Effekt",
                                  "mittlerer Effekt",
                                  "großer Effekt"))
apa_table(d, caption = "Interpretation von Cohen's d.")
```

#### Hedges' g

Eine gelegentlich verwendete Alternative zu Cohen's d ist das Hedges' g. Hedges' g wird weitgehend analog zu Cohen's d verwendet, korrigiert dabei jedoch statistisch für besonders kleine Gruppengößen (N<20) @hedges2014statistical

Es lässt sich mit derselben Funktion berechnen:

```{r}
effsize::cohen.d(Weight.loss ~ Gender, data = data, hedges.correction = TRUE)
```

Die Interpretation von Hedges' g ist identisch wie die von von Cohens'd: 

```{r echo = F}
d = data.frame("g" = c("|>0.2|",
                       "|>0.5|",
                       "|>0.8|"),
               Interpretation = c("kleiner Effekt",
                                  "mittlerer Effekt",
                                  "großer Effekt"))
apa_table(d, caption = "Interpretation von Hedges' g.")
```

### Darstellung in Tabellenform

Zur sauberen Darstellung des Ergebnisses in einer bereits nach APA formatierten Tabelle, lassen sich die Funktionen `apa_print` und `apa_table` aus dem Paket `papaja` verwenden.

```{r}
library(papaja)
apa_test <- apa_print(
 t.test(Weight.loss ~ Gender, data = data)
)
apa_table(
  apa_test$table, caption = "Tabelle für den unabhängigen t-Test."
)
```

## t-Test bei abhängigen Stichproben

```{r include=FALSE}
data = read.csv("data/Paired t-test.csv")
names(data) = c("gewicht_prä", "gewicht_post")
```
### Hypothesen

Mit einem abhängigen t-Test vergleichen wir die Mittelwerte zweier abhängiger Messungen. Ein klassisches Beispiel dafür ist der Vergleich von zwei Messzeitpunkten derselben Variable in derselben Gruppe von Personen.

Im Datensatz muss eine numerische Variable mit Messungen zu zwei Zeiten vorliegen (AV). Die dichotome UV, so wie wir sie vom unabhängigen t-Test kennen ist der Zeitpunkt (z.B. Prä vs. Post).

Es sind folgende Hypothesen denkbar:

Test auf Unterschiedlichkeit der Mittelwerte beider Messungen (ungerichtet):

* $H_0$: $μ_d = 0$
* $H_1$: $μ_d \neq 0$

Test, ob Mittelwert der einen Messung größer/kleiner als Mittelwert der anderen Messung ist (gerichtet):

* $H_0$: $μ_d \leq 0$
* $H_1$: $μ_d > 0$ 

Zum Beispiel könnten wir eine Stichprobe von Personen erhoben haben, die eine Diät durchgeführt haben. Es gäbe eine Messung des Gewichts vor der Diät (Prä), dann erfolgt die Diät und dann gäbe es eine weitere Messung des Gewichts nach der Diät (Post).

Die ersten Zeilen des Stichprobendatensatzes könnten so aussehen:
```{r echo=FALSE}
head(data)
```

Die Testung der Hypothesen erfolgt mathematisch hinsichtlich der Differenz der Wertepaare aller Personen:

```{r}
data$d = data$gewicht_prä - data$gewicht_post

head(data)
```

### Deskriptive Einordnung

Zunächst können wir uns die Deskriptivstatistiken zu beiden Zeitpunkten einmal anschauen:

```{r}
psych::describe(data$gewicht_prä)
psych::describe(data$gewicht_post)
```

Rein deskriptiv lässt sich bereits feststellen, dass das Gewicht zur 1. Messung mit `r round(mean(data$gewicht_prä), 2)`kg etwas höher zu sein scheint, als zur 2. Messung mit `r round(mean(data$gewicht_post), 2)`kg. 

Ob sich dieser numerische Unterschied auch als signifikant erweist, prüfen wir mit dem abhängigen t-Test.

### Test durchführen

Zur Durchführung des Tests nutzen wir die in der Grundform von R vorinstallierte `t.test()` Funktion. 

Die Spezifizierung zur Durchführung eines abhängigen t-Tests erreichen wir mit dem Argument `paired = T`.

Für eine ungerichtete Hypothese:

```{r}
t.test(data$gewicht_prä, data$gewicht_post, paired = T)
```

Für eine gerichtete Hypothese (z.B. Prä-Gewicht höher als Post-Gewicht):

```{r}
t.test(data$gewicht_prä, data$gewicht_post, paired = T, alternative = "greater")
```

### Relevante Parameter extrahieren

Die relevanten Parameter zum Berichten eines abhängigen t-Tests sind:

* $M_d$ (Mittelwert der Differenzen)
* Grenzen des Konfidenzintervalls des Mittelwert der Differenzen
* t-Wert (Teststatistik)
* df (Freiheitsgerade)
* P-Wert

Diese Werte lassen sich wie folgt aus dem t-Test Objekt extrahieren:

t-Wert (Teststatistik):
```{r}
t.test(data$gewicht_prä, data$gewicht_post, paired = T)$statistic
```

df (Freiheitsgerade):
```{r}
t.test(data$gewicht_prä, data$gewicht_post, paired = T)$parameter
```

P-Wert:
```{r}
t.test(data$gewicht_prä, data$gewicht_post, paired = T)$p.value
```

Grenzen des Konfidenzintervalls (unten & oben):
```{r}
t.test(data$gewicht_prä, data$gewicht_post, paired = T)$conf.int[1]
t.test(data$gewicht_prä, data$gewicht_post, paired = T)$conf.int[2]
```

### Voraussetzungsprüfung und Alternativen

Folgende Vorraussetzungen gelten für den abhängigen t-Test:
* abhängige Messungen
* Intervallskala
* Normalverteilung der Differenzwerte 

Sollten die Vorraussetzungen Intervallskalekniveau und Normalverteilung verletzt sein, muss ein robuster Test gerechnet werden (s.u. U-Test).

Die Varianzhomogenität (Voraussetzung beim unabhängigen t-Test) ist beim abhängigen t-Test nicht relevant.

### Effektstärke

#### Cohen's d

Die am häufigsten verwendete Effektstärke für den Vergleich zweier abhängiger Messungen ist Cohen's d @cohen1988statistical.
Cohen's d lässt sich mit dem Paket `effsize` berechnen. Dieses verwendet praktischerweise die gleiche Schreibweise, wie der t-Test. 

VORSICHT: Auch hier muss `paired = T` angegeben werden:

```{r}
effsize::cohen.d(data$gewicht_prä, data$gewicht_post, paired = T)
```

Auch die Einzelparameter von Cohen's d lassen sich extrahieren:

Cohen's d:
```{r}
effsize::cohen.d(data$gewicht_prä, data$gewicht_post, paired = T)$estimate
```

Grenzen des Konfidenzintervalls (unten & oben):
```{r}
effsize::cohen.d(data$gewicht_prä, data$gewicht_post, paired = T)$conf.int[1]
effsize::cohen.d(data$gewicht_prä, data$gewicht_post, paired = T)$conf.int[2]
```

Die Interpretation von Cohens'd lautet wie folgt @cohen1992quantitative:

```{r echo = F}
d = data.frame("d" = c("|>0.2|",
                       "|>0.5|",
                       "|>0.8|"),
               Interpretation = c("kleiner Effekt",
                                  "mittlerer Effekt",
                                  "großer Effekt"))
apa_table(d, caption = "Interpretation von Cohen's d.")
```

### Darstellung in Tabellenform

Zur sauberen Darstellung des Ergebnisses in einer bereits nach APA formatierten Tabelle, lassen sich die Funktionen `apa_print` und `apa_table` aus dem Paket `papaja` verwenden.

```{r}
library(papaja)
apa_test <- apa_print(
 t.test(data$gewicht_prä, data$gewicht_post, paired = T)
)
apa_table(
  apa_test$table, caption = "Tabelle für den abhängigen t-Test."
)
```

## Wilcoxon–Mann–Whitney-U Test (Wilcoxon rank sum test)

Sollten die Vorraussetzungen Intervallskalekniveau und Normalverteilung verletzt sein, muss ein robuster (non-paramterischer) Test gerechnet werden.

Der Wilcoxon–Mann–Whitney-U Test ist eine **Alternative zum unabhängigen t-Test**. 

### Hypothesen

Er prüft im Wesentlichen dieselben Hypothesen, funktioniert aber auf Rangskalenniveau anstelle des Intervallskalenniveaus.

Um beide Tests vergleichen zu können, verwenden wir noch einmal dasselbe Beispiel, wie im Kapitel zum unabhängigen t-Test (Unterschied im Gewichtsverlust nach Diät: Männer vs. Frauen).

```{r include=FALSE}
data = read.csv("data/Independent t-test.csv")
```

### Test durchführen

Der Test nimmt dieselbe Form an wie der abhängige t-Test:

```{r warning=FALSE}
wilcox.test(Weight.loss ~ Gender, data = data, exact = FALSE)
```

Alternative Schreibweise:

```{r warning=FALSE}
wilcox.test(data$Weight.loss[data$Gender == "Males"], data$Weight.loss[data$Gender == "Females"], exact = FALSE)
```

Für einen gerichteten Test (z.B. Frauen nehmen mehr ab als Männer)

```{r warning=FALSE}
wilcox.test(Weight.loss ~ Gender, data = data, alternative = "greater", exact = FALSE)
```

### Relevante Parameter extrahieren

Die relevanten Parameter zum Berichten eines Wilcoxon–Mann–Whitney-U Tests sind:

* Wilcoxon Statistik (W)
* P-Wert

Diese Werte lassen sich wie folgt aus dem t-Test Objekt extrahieren:

Wilcoxon Statistik (W, Teststatistik):
```{r warning=FALSE}
wilcox.test(Weight.loss ~ Gender, data = data, exact = FALSE)$statistic
```

P-Wert:
```{r warning=FALSE}
wilcox.test(Weight.loss ~ Gender, data = data, exact = FALSE)$p.value
```

### Effektstärke

#### Rangsummenkoeffizient $(r)$

Die am häufigsten verwendete Effektstärke für den non-parametrischen Vergleich zweier unabhängiger Gruppen ist der sogenannte Rangsummenkoeffizient [@tomczak2014need].

Der Rangsummenkoeffizient $(r)$ lässt sich mit dem Paket `rstatix` berechnen. Die Funktion lautet `wilcox_effsize()`. Zudem müssen wir vorher das Paket `coin` installieren.

Die Funktion zur Berechnung des Rangsummenkoeffizienten wird wie folgt aufgestellt:

```{r}
rstatix::wilcox_effsize(Weight.loss ~ Gender, data = data)
```

Auch die Einzelparameter des Rangsummenkoeffizient lassen sich extrahieren:

Rangsummenkoeffizient:
```{r}
rstatix::wilcox_effsize(Weight.loss ~ Gender, data = data)$effsize
```

Die Interpretation des Rangsummenkoeffizienten lautet wie folgt:

```{r echo = F}
d = data.frame("r" = c("|>0.1|",
                       "|>0.3|",
                       "|>0.5|"),
               Interpretation = c("kleiner Effekt",
                                  "mittlerer Effekt",
                                  "großer Effekt"))
apa_table(d, caption = "Interpretation des Rangsummenkoeffizienten.")
```

### Darstellung in Tabellenform

Zur sauberen Darstellung des Ergebnisses in einer bereits nach APA formatierten Tabelle, lassen sich die Funktionen `apa_print` und `apa_table` aus dem Paket `papaja` verwenden.

```{r}
library(papaja)
apa_test <- apa_print(
 wilcox.test(Weight.loss ~ Gender, data = data)
)
apa_table(
  apa_test$table, caption = "Tabelle für den Wilcoxon–Mann–Whitney-U Test."
)
```


## Wilcoxon–Mann–U Test (Wilcoxon signed rank test)

Sollten die Vorraussetzungen Intervallskalekniveau und Normalverteilung verletzt sein, muss ein robuster (non-paramterischer) Test gerechnet werden.

Der Wilcoxon–Mann–U Test ist eine **Alternative zum abhängigen t-Test**. 

### Hypothesen

Er prüft im Wesentlichen die selben Hypothesen, funktioniert aber auf Rangskalenniveau anstelle des Intervallskalenniveaus.

Um beide Tests vergleichen zu können, verwenden wir noch einmal dasselbe Beispiel, wie im Kapitel zum abhängigen t-Test (Unterschied im Gewicht: vor einer Diät vs. nach einer Diät).

```{r include=FALSE}
data = read.csv("data/Paired t-test.csv")
names(data) = c("gewicht_prä", "gewicht_post")
```

### Test durchführen

Der Test nimmt die selbe Form an wie der abhängige t-Test:

```{r warning=FALSE}
wilcox.test(data$gewicht_prä, data$gewicht_post, paired = T)
```

Für einen gerichteten Test z.B. Prä-Gewicht höher als Post-Gewicht)

```{r warning=FALSE}
wilcox.test(data$gewicht_prä, data$gewicht_post, paired = T, alternative = "greater")
```

### Relevante Parameter extrahieren

Die relevanten Parameter zum Berichten eines Wilcoxon–Mann–U Tests sind:

* Wilcoxon Statistik (W)
* P-Wert

Diese Werte lassen sich wie folgt aus dem t-Test Objekt extrahieren:

Wilcoxon Statistik (W, Teststatistik):
```{r warning=FALSE}
wilcox.test(data$gewicht_prä, data$gewicht_post, paired = T)$statistic
```

P-Wert:
```{r warning=FALSE}
wilcox.test(data$gewicht_prä, data$gewicht_post, paired = T)$p.value
```

### Effektstärke

#### Rangsummenkoeffizient $(r)$

Die am häufigsten verwendete Effektstärke für den non-parametrischen Vergleich zweier abhängiger Messungen ist der sogenannte Rangsummenkoeffizient @tomczak2014need.

Der Rangsummenkoeffizient $(r)$ lässt sich mit dem Paket `rstatix` berechnen. Die Funktion lautet `wilcox_effsize()`.

Dafür muss der Datensatz jedoch im long-Format (und nicht wie zuvor im wide-Format) vorliegen. Wir transformieren die Daten mit der Funktion `pivot_longer` aus dem `tidyr` R-Paket.

```{r}
data_long = tidyr::pivot_longer(data = data, 
                                cols = c("gewicht_prä", "gewicht_post"), 
                                values_to = "Gewicht",
                                names_to = "Zeitpunkt")

head(data_long)
```

Die Funktion zur Berechnung des Rangsummenkoeffizienten wird wie folgt aufgestellt:

```{r}
rstatix::wilcox_effsize(Gewicht ~ Zeitpunkt, data = data_long, paired = T)
```

Auch die Einzelparameter des Rangsummenkoeffizient lassen sich extrahieren:

Rangsummenkoeffizient:
```{r}
rstatix::wilcox_effsize(Gewicht ~ Zeitpunkt, data = data_long, paired = T)$effsize
```

Die Interpretation des Rangsummenkoeffizienten lautet wie folgt:

```{r echo = F}
d = data.frame("r" = c("|>0.1|",
                       "|>0.3|",
                       "|>0.5|"),
               Interpretation = c("kleiner Effekt",
                                  "mittlerer Effekt",
                                  "großer Effekt"))
apa_table(d, caption = "Interpretation des Rangsummenkoeffizienten.")
```

### Darstellung in Tabellenform

Zur sauberen Darstellung des Ergebnisses in einer bereits nach APA formatierten Tabelle, lassen sich die Funktionen `apa_print` und `apa_table` aus dem Paket `papaja` verwenden.

```{r}
library(papaja)
apa_test <- apa_print(
 wilcox.test(data$gewicht_prä, data$gewicht_post, paired = T)
)
apa_table(
  apa_test$table, caption = "Tabelle für den Wilcoxon–Mann–U Test"
)
```

## $\chi$^2^-Test

Wir haben nun die t-Tests kennengelernt. Diese haben alle gemeinsam, dass Sie Mittelwerte vergleichen. Sie setzen somit voraus, dass die AV numerisch ist.

Wie können wir aber Vergleiche rechnen, wenn unsere AV eine kategoriale (z.B. binäre) Variable ist?

Die verglichene Statistik ist dann die Verteilung, bzw. die Häufigkeit der Ausprägungen der AV anstelle von Mittelwerten.

```{r include=FALSE}
data1 = data.frame(Remission = sample(0:1, 20, replace = T, prob = c(0.5, 0.5)),
                   Therapie = c("Placebo"))
data2 = data.frame(Remission = sample(0:1, 20, replace = T, prob = c(0.2, 0.8)),
                   Therapie = c("Antidepressivum"))
data = rbind(data1, data2)
data$Remission = factor(data$Remission, levels = 0:1, labels = c("Nein", "Ja"))
```

Ein Beispiel für so ein Szenario könnte sein, dass wir ähnlich wie beim unabhängigen t-Test als UV eine binäre Gruppenvariable mit 2 Gruppen haben: 

* Gruppe 1 erhält ein Antidepressivum
* Gruppe 2 erhält ein Placebo.

Die AV könnte der Behandlungserfolg sein, also ob die Personen nach der Behandlung in Remission waren. 

Wir haben also keine numerische AV mehr, für die wir einen Mittelwert bilden könnten, sondern eine Variable mit 2 Stufen (Remission: ja/nein).

### Deskriptive Einordnung

Um uns die Remissionsraten innerhalb der Antidepressivum-Gruppe und der Placebo-Gruppe in einer Häufigkeitstabelle anzusehen, eignet sich der `table()` Befehl:

```{r}
table(data$Remission, data$Therapie)
```

Es lässt sich bereits sehen, dass von insgesamt 20 Personen in der Antidepressivum-Gruppe 17 einen Behandlungserfolg hatten. Von den 20 Personen in der Placebo-Gruppe jedoch nur 8.

Um zu prüfen, ob dieser numerische Unterschied signifikant ist, rechnen wir den $\chi$^2^-Test.

### Test durchführen

Zur Durchführung des $\chi$^2^-Test nutzen wir die in der Grundform von R vorinstallierte `chisq.test()` Funktion. 

Diese umschließt ganz einfach den `table()` Befehl, den wir gerade schon verwendet haben:

```{r}
chisq.test(table(data$Remission, data$Therapie))
```

### Relevante Parameter extrahieren

Die relevanten Parameter zum Berichten eines abhängigen t-Tests sind:

* $\chi$^2^-Wert (Teststatistik)
* df (Freiheitsgerade)
* P-Wert

Diese Werte lassen sich wie folgt aus dem t-Test Objekt extrahieren:

$\chi$^2^-Wert (Teststatistik):
```{r}
chisq.test(table(data$Remission, data$Therapie))$statistic
```

df (Freiheitsgerade):
```{r}
chisq.test(table(data$Remission, data$Therapie))$parameter
```

P-Wert:
```{r}
chisq.test(table(data$Remission, data$Therapie))$p.value
```

### Voraussetzungsprüfung und Alternativen

Folgende Vorraussetzungen gelten für den $\chi$^2^-Test:

* unabhängige Messungen
* Nominalskala
* Jede Zelle der Häufigkeitstabelle hat 5 oder mehr Beobachtungen.

Sollte die Vorraussetzung, dass jede Zelle der Häufigkeitstabelle 5 oder mehr Beobachtungen hat nicht gegeben sein, wird uns R in der Ausgabe darauf hinweisen. Dann muss ersatzweise der exakte Test nach Fisher berechnet werden (s.u.)

### Effektstärke

#### $\phi$-Koeffizient

Wenn wir eine 2x2 dimensionale Häufigkeitstabelle haben, wird als Effektstärke $\phi$ berechnet.

Wir können die Funktion `phi()` aus dem `effectsize` R-Paket verwenden:

```{r message=FALSE, warning=FALSE}
effectsize::phi(chisq.test(table(data$Remission, data$Therapie)))
```

Auch die Einzelparameter von $\phi$ lassen sich extrahieren:

$\phi$:
```{r message=FALSE, warning=FALSE}
effectsize::phi(chisq.test(table(data$Remission, data$Therapie)))$phi_adjusted
```

Grenzen des Konfidenzintervalls (unten & oben):
```{r message=FALSE, warning=FALSE}
effectsize::phi(chisq.test(table(data$Remission, data$Therapie)))$CI_low
effectsize::phi(chisq.test(table(data$Remission, data$Therapie)))$CI_high
```

Die Interpretation von $\phi$ lautet wie folgt @cohen1988statistical:

```{r echo = F}
d = data.frame("φ" = c(">0.1",
                       ">0.3",
                       ">0.5"),
               Interpretation = c("kleiner Effekt",
                                  "mittlerer Effekt",
                                  "großer Effekt"))
apa_table(d, caption = "Interpretation von φ")
```

#### Cramer's $V$ 

Wenn wir eine Häufigkeitstabelle mit mehr als 2x2 Dimensionen haben, wird als Effektstärke Cramer's $V$ berechnet.

Nehmen wir dafür einmal an, unsere Therapieerfolg Variable hätte eine 3. Ausprägung "Rückfall". Das wären Personen, die zunächst eine Remission hatten, dann aber wieder erkranken.

```{r include=FALSE}
data1 = data.frame(Erfolg = sample(0:2, 20, replace = T, prob = c(0.3, 0.3, 0.3)),
                   Therapie = c("Placebo"))
data2 = data.frame(Erfolg = sample(0:2, 20, replace = T, prob = c(0.2, 0.7, 0.1)),
                   Therapie = c("Antidepressivum"))
data = rbind(data1, data2)
data$Erfolg = factor(data$Erfolg, levels = 0:2, labels = c("Nein", "Remission", "Rückfall"))
```

```{r}
table(data$Erfolg, data$Therapie)
```

Wir können die Funktion `cramers_v()` aus dem `effectsize` R-Paket verwenden:

```{r warning=FALSE}
effectsize::cramers_v(chisq.test(table(data$Erfolg, data$Therapie)))
```

Auch die Einzelparameter von Cramer's $V$ lassen sich extrahieren:

Cramer's $V$:
```{r warning=FALSE}
effectsize::cramers_v(chisq.test(table(data$Erfolg, data$Therapie)))$Cramers_v_adjusted
```

Grenzen des Konfidenzintervalls (unten & oben):
```{r warning=FALSE}
effectsize::cramers_v(chisq.test(table(data$Erfolg, data$Therapie)))$CI_low
effectsize::cramers_v(chisq.test(table(data$Erfolg, data$Therapie)))$CI_high
```

Die Interpretation von Cramer's $V$ lautet wie folgt @ellis2010essential:

```{r echo = F}
d = data.frame("r" = c(">0.1",
                       ">0.3",
                       ">0.5"),
               Interpretation = c("kleiner Effekt",
                                  "mittlerer Effekt",
                                  "großer Effekt"))
apa_table(d, caption = "Interpretation des Cramer's V")
```


## Fisher's Exakter Test

Sollte die Vorraussetzung des $\chi$^2^-Tests, dass jede Zelle der Häufigkeitstabelle 5 oder mehr Beobachtungen hat nicht gegeben sein, muss ersatzweise der exakte Test nach Fisher berechnet werden

Dieser funktioniert jedoch im Wesentlichen analog. 

```{r include=FALSE}
set.seed(2)
data1 = data.frame(Remission = sample(0:1, 20, replace = T, prob = c(0.5, 0.5)),
                   Therapie = c("Placebo"))
data2 = data.frame(Remission = sample(0:1, 20, replace = T, prob = c(0.1, 0.8)),
                   Therapie = c("Antidepressivum"))
data = rbind(data1, data2)
data$Remission = factor(data$Remission, levels = 0:1, labels = c("Nein", "Ja"))
```

```{r}
table(data$Remission, data$Therapie)
```

### Test durchführen

Zur Durchführung von Fisher's Exaktem Test nutzen wir die in der Grundform von R vorinstallierte `fisher.test()` Funktion. 

Diese umschließt ganz einfach den `table()` Befehl, den wir gerade schon verwendet haben:

```{r}
fisher.test(table(data$Remission, data$Therapie))
```



